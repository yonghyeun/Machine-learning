{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tqdm import tqdm,trange,tqdm_notebook\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,f1_score\n",
    "import warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rc('font', family = 'malgun gothic')\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/whileduck/Desktop/kaggle/data.csv')\n",
    "origin = pd.read_csv('C:/Users/whileduck/Desktop/kaggle/origin_data.csv')\n",
    "sub = pd.read_csv('C:/Users/whileduck/Desktop/kaggle/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.79</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "      <td>13.79</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.79</td>\n",
       "      <td>686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>1861</td>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>1862</td>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1863</td>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1864</td>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1865</td>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33509 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        author geometry  pressure [MPa]  mass_flux [kg/m2-s]  \\\n",
       "0        0      Thompson     tube            7.00               3770.0   \n",
       "1        1      Thompson     tube             NaN               6049.0   \n",
       "2        2      Thompson      NaN           13.79               2034.0   \n",
       "3        3          Beus  annulus           13.79               3679.0   \n",
       "4        4           NaN     tube           13.79                686.0   \n",
       "...    ...           ...      ...             ...                  ...   \n",
       "1860  1861  Richenderfer    plate            1.01               1500.0   \n",
       "1861  1862  Richenderfer    plate            1.01               1500.0   \n",
       "1862  1863  Richenderfer    plate            1.01               2000.0   \n",
       "1863  1864  Richenderfer    plate            1.01               2000.0   \n",
       "1864  1865  Richenderfer    plate            1.01               2000.0   \n",
       "\n",
       "      x_e_out [-]  D_e [mm]  D_h [mm]  length [mm]  chf_exp [MW/m2]  \n",
       "0          0.1754       NaN      10.8        432.0              3.6  \n",
       "1         -0.0416      10.3      10.3        762.0              6.2  \n",
       "2          0.0335       7.7       7.7        457.0              2.5  \n",
       "3         -0.0279       5.6      15.2       2134.0              3.0  \n",
       "4             NaN      11.1      11.1        457.0              2.8  \n",
       "...           ...       ...       ...          ...              ...  \n",
       "1860      -0.0218      15.0     120.0         10.0              9.4  \n",
       "1861      -0.0434      15.0     120.0         10.0             10.4  \n",
       "1862      -0.0109      15.0     120.0         10.0             10.8  \n",
       "1863      -0.0218      15.0     120.0         10.0             10.9  \n",
       "1864      -0.0434      15.0     120.0         10.0             11.5  \n",
       "\n",
       "[33509 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,origin])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this competition (both train and test) was generated from a deep learning model trained on the Predicting Critical Heat Flux dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n",
    "\n",
    "Files\n",
    "\n",
    "    data.csv - the competition dataset; your objective is to impute the missing values of the feature x_e_out [-] (equilibrium quality)\n",
    "    sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations : RMSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이번 Playground의 주 목적\n",
    "- 데이터프레임에 있는 다양한 결측값을 어떻게 채울 것이냐 \n",
    "- 타겟값은 x_e_out \n",
    "- 컬럼들의 특수 기호를 어떻게 제거하여 사용에 용이하게 할 것이냐 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메모리 용량 줄이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('object')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2.81 MB\n",
      "Memory usage after optimization is: 1.28 MB\n",
      "Decreased by 54.5%\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행 별 갤측값 갯수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행 별 결측값 갯수의 범위 : 0 ~ 10\n"
     ]
    }
   ],
   "source": [
    "max_na = len(df.columns)\n",
    "\n",
    "print(f'행 별 결측값 갯수의 범위 : 0 ~ {max_na}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '결측값 갯수')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na_df = pd.DataFrame(df.isna().sum(axis = 1)).reset_index() # 인덱스 별 결측값 갯수 \n",
    "\n",
    "sns.countplot(data = na_df,\n",
    "                x = 0)\n",
    "plt.title('인덱스 별 결측값 갯수 ')\n",
    "plt.xlabel('결측값 갯수')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 결측치를 채워야 하는 인덱스들은 총 24000 개 정도가 된다. 예측을 위해 \n",
    "\n",
    "* 예전에는 결측치를 모두 평균, 중앙값, 랜덤한 난수 등으로 채워왔으나 머신러닝을 통해 보간하는 방법도 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns 명 변경하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'author', 'geometry', 'pressure', 'mass_flux', 'x_e_out', 'D_e',\n",
       "       'D_h', 'length', 'chf_exp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.map(lambda x: x.split('[')[0].strip())\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_obj = df['x_e_out']\n",
    "df = df.drop('x_e_out',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['author', 'geometry', 'pressure', 'mass_flux', 'D_e', 'D_h', 'length']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value = [col for col in df.columns if df[col].isna().sum() > 0]\n",
    "missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = missing_value[:2]\n",
    "num_cols = missing_value[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affd2b1d7e954eb3b3cb8625f598d15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'multiclass', 'metric': 'multi_logloss', 'verbosity': -1, 'num_boost_round': 112, 'num_class': 10}\n",
      "author 의 Best iteration 은 112.4\n",
      "----------------------------------------\n",
      "author 의 5 번 교차 검증 시 점수\n",
      "Train F1 score : 0.96\n",
      "Test F1 score : 0.95\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20789d1ffcd1422694e66d470fe626d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'multiclass', 'metric': 'multi_logloss', 'verbosity': -1, 'num_boost_round': 121, 'num_class': 3}\n",
      "geometry 의 Best iteration 은 121.0\n",
      "----------------------------------------\n",
      "geometry 의 5 번 교차 검증 시 점수\n",
      "Train F1 score : 0.99\n",
      "Test F1 score : 0.99\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "\n",
    "cv = KFold(n_splits = splits, shuffle = True,\n",
    "            random_state = 42)\n",
    "\n",
    "param_grid = {\n",
    "'learning_rate': [0.1],\n",
    "'num_leaves': [31, 50, 100],\n",
    "'max_depth': [3, 5, 7],\n",
    "'objective': ['multiclass'],\n",
    "'metric': ['multi_logloss'],\n",
    "'verbosity': [-1],\n",
    "'num_boost_round': [300],\n",
    "'early_stopping_rounds': [10]\n",
    "}\n",
    "\n",
    "param_keys = list(param_grid.keys())\n",
    "param_value = list(param_grid.values())\n",
    "\n",
    "\n",
    "labels = {}\n",
    "reverse_labels = {}\n",
    "result_params = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "\n",
    "    cond = df[col].isna() # bool 형태로 condition 저장 \n",
    "    \n",
    "    \n",
    "    data = pd.get_dummies(df.drop(col,axis = 1))\n",
    "    data[col] = df[col]\n",
    "    \n",
    "    train = data[~cond]\n",
    "    test = data[cond]\n",
    "    \n",
    "    # train = df[~cond] # 학습 데이터는 해당 col 이 결측값이 아닌 경우 \n",
    "    # test = pd.get_dummies(df[cond].drop(col,axis = 1)) # 테스트 데이터는 해당 col 이 결측값인 경우\n",
    "    \n",
    "    label = {v:k for k,v in enumerate(train[col].unique())} # 범주형 변수 학습 및 예측을 위해 라벨링\n",
    "    reverse_label = {k:v for k,v in enumerate(train[col].unique())} # 예측 후 원래형태로 돌리기 위한 역 라벨링\n",
    "    \n",
    "    \n",
    "    labels[col] = label # col 별 라벨링 결과를 딕셔너리 형태에 저장 \n",
    "    reverse_labels[col] = reverse_label\n",
    "    \n",
    "    X = pd.get_dummies(train.drop(col,axis = 1)) # col 을 제외한 범주형 변수는 더미 변수화\n",
    "    y = train[col].map(label) #label encoding \n",
    "\n",
    "    # 빈 딕셔너리 형태 생성 \n",
    "\n",
    "    train_avg_scores = {} \n",
    "    test_avg_scores = {}\n",
    "    best_iter = {}\n",
    "    \n",
    "    param_combinations = itertools.product(*param_value) # itertools 를 통해 param_grid 의 모든 조건 수 생성 \n",
    "    \n",
    "    for param in tqdm_notebook(param_combinations): # for 문 이전에 만든 param_grid 를 iteration 하며 gridsearch 와 같이 구현 \n",
    "\n",
    "        new_param_grid = dict(zip(param_keys,param)) # param_grid 에 있는 조건에 따라 new_param_grid 생성\n",
    "        new_param_grid['num_class'] = y.nunique()\n",
    "        \n",
    "        # Fold set 을 돌며 score 가 담길 빈 변수 생성 \n",
    "        \n",
    "        train_score = 0 \n",
    "        test_score = 0\n",
    "        iter = 0\n",
    "                \n",
    "        for i,(train_idx,test_idx) in enumerate(cv.split(X,y)):\n",
    "            \n",
    "            \n",
    "            x_train,y_train = X.iloc[train_idx],y.iloc[train_idx]\n",
    "            x_test,y_test = X.iloc[test_idx],y.iloc[test_idx]\n",
    "            \n",
    "            train_data = lgb.Dataset(data = x_train, label = y_train)\n",
    "            test_data = lgb.Dataset(data = x_test, label = y_test)\n",
    "            \n",
    "            model = lgb.train(new_param_grid,train_data,\n",
    "                        valid_sets = [test_data], verbose_eval = False)\n",
    "            \n",
    "            cv_best_iter = model.best_iteration # early stopping 이후 best_iteration 수를 생성 \n",
    "            \n",
    "            # multi class 분류 문제는 해당 class 별 probability 로 예측 \n",
    "            \n",
    "            train_pred_prob = model.predict(x_train, num_iteration = cv_best_iter)\n",
    "            test_pred_prob = model.predict(x_test, num_iteration = cv_best_iter)\n",
    "            \n",
    "            # np.argmax 를 통해 class 별 probability 가 가장 높은 인덱스를 예측값 리스트 형태로 저장 \n",
    "            \n",
    "            train_pred = np.argmax(train_pred_prob,axis = 1)\n",
    "            test_pred = np.argmax(test_pred_prob,axis = 1)\n",
    "            \n",
    "            # Fold 별 평균 score 저장 \n",
    "            \n",
    "            train_score += f1_score(y_train,train_pred,average = 'micro') \n",
    "            test_score += f1_score(y_test,test_pred, average = 'micro') \n",
    "            iter += cv_best_iter\n",
    "        \n",
    "        # iteration 동안 생성된 평균 score를 딕셔너리에 저장     \n",
    "        \n",
    "        train_avg_scores[param] = train_score / splits \n",
    "        test_avg_scores[param] = test_score / splits\n",
    "        best_iter[param] = iter / splits\n",
    "\n",
    "\n",
    "    # iteration 돌며 생긴 다양한 parmeter 값들 중 가장 test_f1_score가 높은 key 를 test_best_params에 저장 \n",
    "    test_best_params = max(test_avg_scores, key = test_avg_scores.get)\n",
    "\n",
    "    # 다시 lgb_train 에 적용 할 수 있도록 딕셔너리 컴프리헨션으로 딕셔너리 형태로 저장 \n",
    "\n",
    "    best_params = {v:k for k,v in zip(list(test_best_params),list(new_param_grid.keys())[:-1])}\n",
    "    \n",
    "    del best_params['early_stopping_rounds'] # test 할 때 early_stopping 기능은 사용하지 않을 것이니 제거\n",
    "    best_params['num_boost_round'] = int(best_iter[test_best_params]) # num_boost_round 는 해당 params 의 best_iteations 수로 지정 \n",
    "    best_params['num_class'] =  y.nunique() # num_class 지정 \n",
    "    result_params[col] = best_params\n",
    "\n",
    "\n",
    "    print(f'{col} 의 Best Parameter 는 {best_params}')\n",
    "    print(f'{col} 의 Best iteration 은 {best_iter[test_best_params]}')\n",
    "    print('--'*20)\n",
    "    print(f'{col} 의 {splits} 번 교차 검증 시 점수')\n",
    "    print(f'Train F1 score : {round(train_avg_scores[test_best_params],2)}')\n",
    "    print(f'Test F1 score : {round(test_avg_scores[test_best_params],2)}')\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    \n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    cond = data[col].isna()\n",
    "    \n",
    "    feature_data = pd.get_dummies(data.loc[~cond].drop(col,axis = 1))\n",
    "    label_data = data.loc[~cond,col].map(labels[col])\n",
    "    \n",
    "    test = pd.get_dummies(data[cond])\n",
    "    \n",
    "    lgb_data = lgb.Dataset(data = feature_data,\n",
    "                label = label_data)\n",
    "    \n",
    "    model = lgb.train(result_params[col], lgb_data)\n",
    "    \n",
    "    prob = model.predict(test)\n",
    "    pred = np.argmax(prob, axis = 1)\n",
    "    \n",
    "    df[col] = df[col].map(labels[col])\n",
    "    df.loc[cond,col] = pred\n",
    "    \n",
    "    df[col] = df[col].map(reverse_labels[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pressure</th>\n",
       "      <th>mass_flux</th>\n",
       "      <th>D_e</th>\n",
       "      <th>D_h</th>\n",
       "      <th>length</th>\n",
       "      <th>chf_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.796875</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6048.0</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>10.296875</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.789062</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>7.699219</td>\n",
       "      <td>7.699219</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "      <td>13.789062</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>5.601562</td>\n",
       "      <td>15.203125</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weatherhead</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.789062</td>\n",
       "      <td>686.0</td>\n",
       "      <td>11.101562</td>\n",
       "      <td>11.101562</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>Richenderfer</td>\n",
       "      <td>plate</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33509 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            author geometry   pressure  mass_flux        D_e         D_h  \\\n",
       "0         Thompson     tube   7.000000     3770.0        NaN   10.796875   \n",
       "1         Thompson     tube        NaN     6048.0  10.296875   10.296875   \n",
       "2         Thompson     tube  13.789062     2034.0   7.699219    7.699219   \n",
       "3             Beus  annulus  13.789062     3680.0   5.601562   15.203125   \n",
       "4      Weatherhead     tube  13.789062      686.0  11.101562   11.101562   \n",
       "...            ...      ...        ...        ...        ...         ...   \n",
       "1860  Richenderfer    plate   1.009766     1500.0  15.000000  120.000000   \n",
       "1861  Richenderfer    plate   1.009766     1500.0  15.000000  120.000000   \n",
       "1862  Richenderfer    plate   1.009766     2000.0  15.000000  120.000000   \n",
       "1863  Richenderfer    plate   1.009766     2000.0  15.000000  120.000000   \n",
       "1864  Richenderfer    plate   1.009766     2000.0  15.000000  120.000000   \n",
       "\n",
       "      length    chf_exp  \n",
       "0      432.0   3.599609  \n",
       "1      762.0   6.199219  \n",
       "2      457.0   2.500000  \n",
       "3     2134.0   3.000000  \n",
       "4      457.0   2.800781  \n",
       "...      ...        ...  \n",
       "1860    10.0   9.398438  \n",
       "1861    10.0  10.398438  \n",
       "1862    10.0  10.796875  \n",
       "1863    10.0  10.898438  \n",
       "1864    10.0  11.500000  \n",
       "\n",
       "[33509 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조건 수 : 9\n",
      "fitting 수 : 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:19,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 300}\n",
      "pressure 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 299}\n",
      "pressure 의 Best iteration 은 299.8\n",
      "----------------------------------------\n",
      "pressure 의 5 번 교차 검증 시 점수\n",
      "Train mse : 4.08\n",
      "Test mse : 4.28\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:12,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 300}\n",
      "mass_flux 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 299}\n",
      "mass_flux 의 Best iteration 은 299.0\n",
      "----------------------------------------\n",
      "mass_flux 의 5 번 교차 검증 시 점수\n",
      "Train mse : 1534324.85\n",
      "Test mse : 1592383.69\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:20,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 300}\n",
      "D_e 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 299}\n",
      "D_e 의 Best iteration 은 299.6\n",
      "----------------------------------------\n",
      "D_e 의 5 번 교차 검증 시 점수\n",
      "Train mse : 0.9\n",
      "Test mse : 1.0\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:15,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 100, 'max_depth': 7, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 300}\n",
      "D_h 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 100, 'max_depth': 7, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 167}\n",
      "D_h 의 Best iteration 은 167.8\n",
      "----------------------------------------\n",
      "D_h 의 5 번 교차 검증 시 점수\n",
      "Train mse : 4.94\n",
      "Test mse : 10.61\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:23,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 300}\n",
      "length 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'objective': 'regression', 'metric': 'mse', 'verbosity': -1, 'num_boost_round': 299}\n",
      "length 의 Best iteration 은 299.8\n",
      "----------------------------------------\n",
      "length 의 5 번 교차 검증 시 점수\n",
      "Train mse : 52184.25\n",
      "Test mse : 54977.15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "splits = 5\n",
    "\n",
    "cv = KFold(n_splits = splits, shuffle = True,\n",
    "            random_state = 42)\n",
    "\n",
    "param_grid = {\n",
    "'learning_rate': [0.1],\n",
    "'num_leaves': [31, 50, 100],\n",
    "'max_depth': [3, 5, 7],\n",
    "'objective': ['regression'],\n",
    "'metric': ['mse'],\n",
    "'verbosity': [-1],\n",
    "'num_boost_round': [300],\n",
    "'early_stopping_rounds': [10]\n",
    "}\n",
    "\n",
    "\n",
    "param_keys = list(param_grid.keys())\n",
    "param_value = list(param_grid.values())\n",
    "\n",
    "result_params = {}\n",
    "\n",
    "for _,col in enumerate(num_cols):\n",
    "    \n",
    "    cond = df[col].isna() # bool 형태로 condition 저장 \n",
    "\n",
    "    data = pd.get_dummies(df.drop(col,axis = 1))\n",
    "    data[col] = df[col]\n",
    "    \n",
    "    train = data[~cond]\n",
    "    test = data[cond]\n",
    "\n",
    "    \n",
    "    X = train.drop(col,axis = 1) # col 을 제외한 범주형 변수는 더미 변수화\n",
    "    y = train[col] #label encoding \n",
    "    \n",
    "\n",
    "    # 빈 딕셔너리 형태 생성 \n",
    "\n",
    "    train_avg_scores = {} \n",
    "    test_avg_scores = {}\n",
    "    best_iter = {}\n",
    "    \n",
    "        \n",
    "    \n",
    "    if _ == 0:\n",
    "        \n",
    "        param_combinations = itertools.product(*param_value) # itertools 를 통해 param_grid 의 모든 조건 수 생성 \n",
    "        num_combinations = len(list(itertools.product(*param_value)))\n",
    "        \n",
    "        print('조건 수 :',num_combinations)\n",
    "        print('fitting 수 :', num_combinations * splits)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        param_combinations = itertools.product(*param_value) # itertools 를 통해 param_grid 의 모든 조건 수 생성 \n",
    "\n",
    "    \n",
    "    for param in tqdm(param_combinations): # for 문 이전에 만든 param_grid 를 iteration 하며 gridsearch 와 같이 구현 \n",
    "\n",
    "        new_param_grid = dict(zip(param_keys,param)) # param_grid 에 있는 조건에 따라 new_param_grid 생성\n",
    "        \n",
    "        \n",
    "        # Fold set 을 돌며 score 가 담길 빈 변수 생성 \n",
    "        \n",
    "        train_score = 0 \n",
    "        test_score = 0\n",
    "        iter = 0\n",
    "                \n",
    "        for i,(train_idx,test_idx) in enumerate(cv.split(X,y)):\n",
    "            \n",
    "            \n",
    "            x_train,y_train = X.iloc[train_idx],y.iloc[train_idx]\n",
    "            x_test,y_test = X.iloc[test_idx],y.iloc[test_idx]\n",
    "\n",
    "            train_data = lgb.Dataset(data = x_train, label = y_train)\n",
    "            test_data = lgb.Dataset(data = x_test, label = y_test)\n",
    "            \n",
    "            model = lgb.train(new_param_grid,train_data,\n",
    "                        valid_sets = [test_data], verbose_eval = False)\n",
    "            \n",
    "            cv_best_iter = model.best_iteration # early stopping 이후 best_iteration 수를 생성 \n",
    "            \n",
    "            # multi class 분류 문제는 해당 class 별 probability 로 예측 \n",
    "            \n",
    "            train_pred = model.predict(x_train, num_iteration = cv_best_iter)\n",
    "            test_pred= model.predict(x_test, num_iteration = cv_best_iter)\n",
    "            \n",
    "            # Fold 별 평균 score 저장 \n",
    "            \n",
    "            train_score += mean_squared_error(y_train,train_pred) \n",
    "            test_score += mean_squared_error(y_test,test_pred) \n",
    "                        \n",
    "            iter += cv_best_iter\n",
    "        \n",
    "        # iteration 동안 생성된 평균 score를 딕셔너리에 저장     \n",
    "        \n",
    "        train_avg_scores[param] = train_score / splits \n",
    "        test_avg_scores[param] = test_score / splits\n",
    "        best_iter[param] = iter / splits\n",
    "\n",
    "\n",
    "    # iteration 돌며 생긴 다양한 parmeter 값들 중 가장 test_f1_score가 높은 key 를 test_best_params에 저장 \n",
    "    test_best_params = max(test_avg_scores, key = test_avg_scores.get)\n",
    "\n",
    "    # 다시 lgb_train 에 적용 할 수 있도록 딕셔너리 컴프리헨션으로 딕셔너리 형태로 저장 \n",
    "\n",
    "    best_params = {v:k for k,v in zip(list(test_best_params),list(new_param_grid.keys())[:-1])}\n",
    "    \n",
    "    print(best_params)\n",
    "    \n",
    "    best_params['num_boost_round'] = int(best_iter[test_best_params]) # num_boost_round 는 해당 params 의 best_iteations 수로 지정 \n",
    "    result_params[col] = best_params\n",
    "\n",
    "\n",
    "    print(f'{col} 의 Best Parameter 는 {best_params}')\n",
    "    print(f'{col} 의 Best iteration 은 {best_iter[test_best_params]}')\n",
    "    print('--'*20)\n",
    "    print(f'{col} 의 {splits} 번 교차 검증 시 점수')\n",
    "    print(f'Train mse : {round(train_avg_scores[test_best_params],2)}')\n",
    "    print(f'Test mse : {round(test_avg_scores[test_best_params],2)}')\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure</th>\n",
       "      <th>mass_flux</th>\n",
       "      <th>D_e</th>\n",
       "      <th>D_h</th>\n",
       "      <th>length</th>\n",
       "      <th>chf_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.905700e+04</td>\n",
       "      <td>28718.0</td>\n",
       "      <td>2.802100e+04</td>\n",
       "      <td>2.892000e+04</td>\n",
       "      <td>28750.0</td>\n",
       "      <td>3.350900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.332031e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>5.273438e+00</td>\n",
       "      <td>1.992188e+01</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.984375e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.997559e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.998047e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.890625e+00</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.601562e+00</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2.400391e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.103125e+01</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>7.800781e+00</td>\n",
       "      <td>1.029688e+01</td>\n",
       "      <td>610.0</td>\n",
       "      <td>3.400391e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.378906e+01</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>1.079688e+01</td>\n",
       "      <td>1.150000e+01</td>\n",
       "      <td>914.0</td>\n",
       "      <td>4.601562e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.068750e+01</td>\n",
       "      <td>7976.0</td>\n",
       "      <td>3.750000e+01</td>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>3048.0</td>\n",
       "      <td>1.929688e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pressure  mass_flux           D_e           D_h   length  \\\n",
       "count  2.905700e+04    28718.0  2.802100e+04  2.892000e+04  28750.0   \n",
       "mean            inf        inf           inf           inf      inf   \n",
       "std    4.332031e+00        inf  5.273438e+00  1.992188e+01      inf   \n",
       "min    9.997559e-02        0.0  1.000000e+00  1.000000e+00     10.0   \n",
       "25%    6.890625e+00     1519.0  5.000000e+00  5.601562e+00    318.0   \n",
       "50%    1.103125e+01     2728.0  7.800781e+00  1.029688e+01    610.0   \n",
       "75%    1.378906e+01     4068.0  1.079688e+01  1.150000e+01    914.0   \n",
       "max    2.068750e+01     7976.0  3.750000e+01  1.200000e+02   3048.0   \n",
       "\n",
       "            chf_exp  \n",
       "count  3.350900e+04  \n",
       "mean            inf  \n",
       "std    1.984375e+00  \n",
       "min    7.998047e-01  \n",
       "25%    2.400391e+00  \n",
       "50%    3.400391e+00  \n",
       "75%    4.601562e+00  \n",
       "max    1.929688e+01  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['pressure','D_e','D_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    \n",
    "    data = pd.get_dummies(df.copy())\n",
    "    \n",
    "    cond = data[col].isna()\n",
    "    \n",
    "    feature_data = data.loc[~cond].drop(col,axis = 1)\n",
    "    label_data = data.loc[~cond,col]\n",
    "    \n",
    "    test = data[cond].drop(col,axis = 1)\n",
    "    \n",
    "    lgb_data = lgb.Dataset(data = feature_data,\n",
    "                label = label_data)\n",
    "    \n",
    "    model = lgb.train(result_params[col], lgb_data)\n",
    "    \n",
    "    pred = model.predict(test)\n",
    "    \n",
    "    df.loc[cond,col] = pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mass_flux 와 length 는 mse 가 너무 높았기에 중앙값으로 대치해보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['mass_flux', 'length']:\n",
    "    \n",
    "    cond = df[col].isna()\n",
    "    \n",
    "    df.loc[cond,col] = df.loc[cond,col].fillna(df.loc[~cond,col].median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = submission_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:39,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "cond = df['target'].isna()\n",
    "\n",
    "data = pd.get_dummies(df)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_samples': [20, 50, 100],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'reg_alpha': [0.1],\n",
    "    'reg_lambda':  [0.1],\n",
    "    'verbosity': [-1],\n",
    "    'n_estimators': [1000],\n",
    "    'early_stopping_rounds': [10]\n",
    "}\n",
    "\n",
    "\n",
    "param_keys = list(param_grid.keys())\n",
    "param_value = list(param_grid.values())\n",
    "\n",
    "train = data[~cond]\n",
    "test = data[cond].drop('target',axis = 1)\n",
    "\n",
    "X,y = train.drop('target',axis = 1), train['target']\n",
    "\n",
    "train_avg_scores = {} \n",
    "test_avg_scores = {}\n",
    "best_iter = {}\n",
    "\n",
    "splits = 5\n",
    "\n",
    "cv = KFold(n_splits = splits, shuffle = True,\n",
    "            random_state = 42)\n",
    "\n",
    "param_combinations = itertools.product(*param_value) # itertools 를 통해 param_grid 의 모든 조건 수 생성 \n",
    "\n",
    "for param in tqdm(param_combinations): # for 문 이전에 만든 param_grid 를 iteration 하며 gridsearch 와 같이 구현 \n",
    "\n",
    "    new_param_grid = dict(zip(param_keys,param)) # param_grid 에 있는 조건에 따라 new_param_grid 생성\n",
    "    \n",
    "    # Fold set 을 돌며 score 가 담길 빈 변수 생성 \n",
    "    \n",
    "    train_score = 0 \n",
    "    test_score = 0\n",
    "    iter = 0\n",
    "            \n",
    "    for i,(train_idx,test_idx) in enumerate(cv.split(X,y)):\n",
    "        \n",
    "        \n",
    "        x_train,y_train = X.iloc[train_idx],y.iloc[train_idx]\n",
    "        x_test,y_test = X.iloc[test_idx],y.iloc[test_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(data = x_train, label = y_train)\n",
    "        test_data = lgb.Dataset(data = x_test, label = y_test)\n",
    "        \n",
    "        model = lgb.train(new_param_grid,train_data,\n",
    "                    valid_sets = [test_data], verbose_eval = False)\n",
    "        \n",
    "        cv_best_iter = model.best_iteration # early stopping 이후 best_iteration 수를 생성 \n",
    "        \n",
    "        # multi class 분류 문제는 해당 class 별 probability 로 예측 \n",
    "        \n",
    "        train_pred = model.predict(x_train, num_iteration = cv_best_iter)\n",
    "        test_pred= model.predict(x_test, num_iteration = cv_best_iter)\n",
    "        \n",
    "        # Fold 별 평균 score 저장 \n",
    "        \n",
    "        train_score += mean_squared_error(y_train,train_pred) \n",
    "        test_score += mean_squared_error(y_test,test_pred) \n",
    "                    \n",
    "        iter += cv_best_iter\n",
    "    \n",
    "    # iteration 동안 생성된 평균 score를 딕셔너리에 저장     \n",
    "    \n",
    "    train_avg_scores[param] = train_score / splits \n",
    "    test_avg_scores[param] = test_score / splits\n",
    "    best_iter[param] = iter / splits\n",
    "    \n",
    "\n",
    "# iteration 돌며 생긴 다양한 parmeter 값들 중 가장 test_f1_score가 높은 key 를 test_best_params에 저장 \n",
    "test_best_params = max(test_avg_scores, key = test_avg_scores.get)\n",
    "\n",
    "# 다시 lgb_train 에 적용 할 수 있도록 딕셔너리 컴프리헨션으로 딕셔너리 형태로 저장 \n",
    "\n",
    "best_params = {v:k for k,v in zip(list(test_best_params),list(new_param_grid.keys())[:-1])}\n",
    "\n",
    "\n",
    "best_params['num_boost_round'] = int(best_iter[test_best_params]) # num_boost_round 는 해당 params 의 best_iteations 수로 지정 \n",
    "result_params['target'] = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 의 Best Parameter 는 {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 3, 'min_child_samples': 50, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'verbosity': -1, 'n_estimators': 1000, 'num_boost_round': 338}\n",
      "target 의 Best iteration 은 338.8\n",
      "----------------------------------------\n",
      "target 의 5 번 교차 검증 시 점수\n",
      "Train mse : 0.0050318\n",
      "Test mse : 0.0053496\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'target 의 Best Parameter 는 {best_params}')\n",
    "print(f'target 의 Best iteration 은 {best_iter[test_best_params]}')\n",
    "print('--'*20)\n",
    "print(f'target 의 {splits} 번 교차 검증 시 점수')\n",
    "print(f'Train mse : {round(train_avg_scores[test_best_params],7)}')\n",
    "print(f'Test mse : {round(test_avg_scores[test_best_params],7)}')\n",
    "print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lgb.Dataset(X,y)\n",
    "model = lgb.train(result_params['target'], data)\n",
    "\n",
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['x_e_out [-]'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.010263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.080442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.048425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.009596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td>31633</td>\n",
       "      <td>0.067527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>31634</td>\n",
       "      <td>-0.048729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10412</th>\n",
       "      <td>31637</td>\n",
       "      <td>0.018883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10413</th>\n",
       "      <td>31640</td>\n",
       "      <td>-0.059481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10414</th>\n",
       "      <td>31642</td>\n",
       "      <td>-0.012372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10415 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  x_e_out [-]\n",
       "0          4    -0.010263\n",
       "1          7    -0.080442\n",
       "2         10    -0.048425\n",
       "3         12    -0.009596\n",
       "4         23     0.044800\n",
       "...      ...          ...\n",
       "10410  31633     0.067527\n",
       "10411  31634    -0.048729\n",
       "10412  31637     0.018883\n",
       "10413  31640    -0.059481\n",
       "10414  31642    -0.012372\n",
       "\n",
       "[10415 rows x 2 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('하이퍼파라미터조정.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
